{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "30d9e90f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langgraph.graph import StateGraph, START,END\n",
    "from typing import TypedDict\n",
    "from langchain_community.llms import ollama\n",
    "from langchain_community.chat_models import ChatOllama\n",
    "from langchain_core.output_parsers import PydanticOutputParser\n",
    "from langchain_core.prompts import PromptTemplate\n",
    "from langchain.chains import LLMChain\n",
    "from pydantic import BaseModel, Field\n",
    "import json\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46ea155a",
   "metadata": {},
   "source": [
    "# define state "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b0318b6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class structurestate(BaseModel):\n",
    "    essay:str =Field(description='It will be text.')\n",
    "    feedback:str =Field(description='summary of essay in text.')\n",
    "    score:int =Field(description='score out of 100',ge=0,le=100)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a353a08c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class structurestate(TypedDict):\n",
    "    essay:str \n",
    "    feedback:str \n",
    "    score:int "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86ed7e13",
   "metadata": {},
   "source": [
    "# define graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b92424b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "graph=StateGraph(structurestate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "503195f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Ashish\\AppData\\Local\\Temp\\ipykernel_23584\\2969955315.py:1: LangChainDeprecationWarning: The class `ChatOllama` was deprecated in LangChain 0.3.1 and will be removed in 1.0.0. An updated version of the class exists in the :class:`~langchain-ollama package and should be used instead. To use it run `pip install -U :class:`~langchain-ollama` and import as `from :class:`~langchain_ollama import ChatOllama``.\n",
      "  llm_model=ChatOllama(model='llama3')\n"
     ]
    }
   ],
   "source": [
    "llm_model=ChatOllama(model='llama3')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "dbe15056",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def read_essay(state:structurestate)->structurestate:\n",
    "#     with open(\"essay.txt\",\"r\",encoding=\"utf-8\") as f:\n",
    "#         essay_test=f.read()\n",
    "#     #state['essay']=essay_test# if state Dict\n",
    "#     state.essay=essay_test\n",
    "#     return state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3e94cbfb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def SummariseWithLLM(state:structurestate)->structurestate:\n",
    "#     essay=state['essay']\n",
    "#     feedback=state['feedback']\n",
    "#     score=state['score']\n",
    "#     #parser\n",
    "#     parser=PydanticOutputParser(pydantic_object=structurestate)\n",
    "#     #promt\n",
    "#     promt=PromptTemplate(\n",
    "#         template=(\n",
    "#             \"write feedback on the essay and score out of 100 and provide feedback.\\n\"\n",
    "#             \"Essay: {essay}\\n\\n\"\n",
    "#             \"{format_instructions}\"\n",
    "#         ),\n",
    "#         input_variables=[\"essay\"],   # only \"essay\" is required\n",
    "#         partial_variables={          # format_instructions is auto-filled\n",
    "#             \"format_instructions\": parser.get_format_instructions()\n",
    "#         },\n",
    "#     )\n",
    "#     llm_model=ChatOllama(model=\"llama3\")\n",
    "#     chain=LLMChain(prompt=promt,llm=llm_model,output_parser=parser)\n",
    "#     result=chain.invoke({\"essay\":essay})\n",
    "#     feedback_obj = result \n",
    "#     feedback=feedback_obj.feedback\n",
    "#     score=feedback_obj.score\n",
    "#     return state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "cc421653",
   "metadata": {},
   "outputs": [],
   "source": [
    "def SummariseWithLLM(state: structurestate) -> structurestate:\n",
    "    prompt = PromptTemplate(\n",
    "        template=(\n",
    "            \"Write feedback on the essay and give a score out of 100.\\n\"\n",
    "            \"Essay: {essay}\\n\\n\"\n",
    "            \"Respond in JSON with keys: feedback, score\"\n",
    "        ),\n",
    "        input_variables=[\"essay\"],\n",
    "    )\n",
    "\n",
    "    llm_model = ChatOllama(model=\"llama3\")\n",
    "    chain = LLMChain(prompt=prompt, llm=llm_model)\n",
    "\n",
    "    result = chain.invoke({\"essay\": state[\"essay\"]})\n",
    "    parsed = json.loads(result[\"text\"])\n",
    "\n",
    "    state[\"feedback\"] = parsed[\"feedback\"]\n",
    "    state[\"score\"] = parsed[\"score\"]\n",
    "    return state"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7af2a337",
   "metadata": {},
   "source": [
    "# define node"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8da95e8a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<langgraph.graph.state.StateGraph at 0x1f0af7f3a60>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#graph.add_node(\"read_essay\",read_essay)\n",
    "graph.add_node(\"SummariseWithLLM\",SummariseWithLLM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ed4f6593",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<langgraph.graph.state.StateGraph at 0x1f0af7f3a60>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#graph.add_edge(START,'read_essay')\n",
    "graph.add_edge(START,'SummariseWithLLM')\n",
    "graph.add_edge('SummariseWithLLM',END)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "11a7c958",
   "metadata": {},
   "outputs": [],
   "source": [
    "Workflow=graph.compile()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a02cface",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<langgraph.graph.state.CompiledStateGraph object at 0x000001F0ACF62F50>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Workflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "9504bd43",
   "metadata": {},
   "outputs": [],
   "source": [
    "essay='''Technology today has become an inseparable part of our daily lives, shaping how we work, learn, communicate, and entertain ourselves. From artificial intelligence and cloud computing to biotechnology and renewable energy, innovations are transforming industries and society at an unprecedented pace.\n",
    "\n",
    "One of the most influential advancements is artificial intelligence (AI), which powers everything from voice assistants and recommendation systems to autonomous vehicles and medical diagnostics. AI is not only improving efficiency but also enabling solutions to complex global challenges, such as climate change and healthcare accessibility.\n",
    "\n",
    "Similarly, the rise of 5G and advanced connectivity has accelerated the digital revolution by making information and services accessible in real time, enhancing opportunities for remote work, online education, and telemedicine. Coupled with cloud computing, businesses can now scale faster, innovate more easily, and operate globally with fewer limitations.\n",
    "\n",
    "However, while technology provides remarkable benefits, it also poses significant challenges. Issues such as data privacy, cybersecurity threats, digital addiction, and the widening digital divide must be carefully managed. Furthermore, the rapid pace of automation raises questions about the future of jobs and the need for continuous reskilling.\n",
    "\n",
    "In conclusion, today’s technology is a double-edged sword—capable of bringing about tremendous progress but also requiring responsible use and thoughtful governance. If balanced well, it has the power to create a future that is smarter, more sustainable, and inclusive for all.\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "dc090ab1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Ashish\\AppData\\Local\\Temp\\ipykernel_23584\\3195977501.py:12: LangChainDeprecationWarning: The class `LLMChain` was deprecated in LangChain 0.1.17 and will be removed in 1.0. Use :meth:`~RunnableSequence, e.g., `prompt | llm`` instead.\n",
      "  chain = LLMChain(prompt=prompt, llm=llm_model)\n"
     ]
    },
    {
     "ename": "JSONDecodeError",
     "evalue": "Expecting value: line 1 column 1 (char 0)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mJSONDecodeError\u001b[0m                           Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[14], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[43mWorkflow\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minvoke\u001b[49m\u001b[43m(\u001b[49m\u001b[43m{\u001b[49m\n\u001b[0;32m      2\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43messay\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43messay\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m      3\u001b[0m \u001b[43m}\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32md:\\python_exercises\\env\\lib\\site-packages\\langgraph\\pregel\\main.py:3026\u001b[0m, in \u001b[0;36mPregel.invoke\u001b[1;34m(self, input, config, context, stream_mode, print_mode, output_keys, interrupt_before, interrupt_after, durability, **kwargs)\u001b[0m\n\u001b[0;32m   3023\u001b[0m chunks: \u001b[38;5;28mlist\u001b[39m[\u001b[38;5;28mdict\u001b[39m[\u001b[38;5;28mstr\u001b[39m, Any] \u001b[38;5;241m|\u001b[39m Any] \u001b[38;5;241m=\u001b[39m []\n\u001b[0;32m   3024\u001b[0m interrupts: \u001b[38;5;28mlist\u001b[39m[Interrupt] \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m-> 3026\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m chunk \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstream(\n\u001b[0;32m   3027\u001b[0m     \u001b[38;5;28minput\u001b[39m,\n\u001b[0;32m   3028\u001b[0m     config,\n\u001b[0;32m   3029\u001b[0m     context\u001b[38;5;241m=\u001b[39mcontext,\n\u001b[0;32m   3030\u001b[0m     stream_mode\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mupdates\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mvalues\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[0;32m   3031\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m stream_mode \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mvalues\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   3032\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m stream_mode,\n\u001b[0;32m   3033\u001b[0m     print_mode\u001b[38;5;241m=\u001b[39mprint_mode,\n\u001b[0;32m   3034\u001b[0m     output_keys\u001b[38;5;241m=\u001b[39moutput_keys,\n\u001b[0;32m   3035\u001b[0m     interrupt_before\u001b[38;5;241m=\u001b[39minterrupt_before,\n\u001b[0;32m   3036\u001b[0m     interrupt_after\u001b[38;5;241m=\u001b[39minterrupt_after,\n\u001b[0;32m   3037\u001b[0m     durability\u001b[38;5;241m=\u001b[39mdurability,\n\u001b[0;32m   3038\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[0;32m   3039\u001b[0m ):\n\u001b[0;32m   3040\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m stream_mode \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mvalues\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m   3041\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(chunk) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m2\u001b[39m:\n",
      "File \u001b[1;32md:\\python_exercises\\env\\lib\\site-packages\\langgraph\\pregel\\main.py:2647\u001b[0m, in \u001b[0;36mPregel.stream\u001b[1;34m(self, input, config, context, stream_mode, print_mode, output_keys, interrupt_before, interrupt_after, durability, subgraphs, debug, **kwargs)\u001b[0m\n\u001b[0;32m   2645\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m task \u001b[38;5;129;01min\u001b[39;00m loop\u001b[38;5;241m.\u001b[39mmatch_cached_writes():\n\u001b[0;32m   2646\u001b[0m     loop\u001b[38;5;241m.\u001b[39moutput_writes(task\u001b[38;5;241m.\u001b[39mid, task\u001b[38;5;241m.\u001b[39mwrites, cached\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m-> 2647\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m _ \u001b[38;5;129;01min\u001b[39;00m runner\u001b[38;5;241m.\u001b[39mtick(\n\u001b[0;32m   2648\u001b[0m     [t \u001b[38;5;28;01mfor\u001b[39;00m t \u001b[38;5;129;01min\u001b[39;00m loop\u001b[38;5;241m.\u001b[39mtasks\u001b[38;5;241m.\u001b[39mvalues() \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m t\u001b[38;5;241m.\u001b[39mwrites],\n\u001b[0;32m   2649\u001b[0m     timeout\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstep_timeout,\n\u001b[0;32m   2650\u001b[0m     get_waiter\u001b[38;5;241m=\u001b[39mget_waiter,\n\u001b[0;32m   2651\u001b[0m     schedule_task\u001b[38;5;241m=\u001b[39mloop\u001b[38;5;241m.\u001b[39maccept_push,\n\u001b[0;32m   2652\u001b[0m ):\n\u001b[0;32m   2653\u001b[0m     \u001b[38;5;66;03m# emit output\u001b[39;00m\n\u001b[0;32m   2654\u001b[0m     \u001b[38;5;28;01myield from\u001b[39;00m _output(\n\u001b[0;32m   2655\u001b[0m         stream_mode, print_mode, subgraphs, stream\u001b[38;5;241m.\u001b[39mget, queue\u001b[38;5;241m.\u001b[39mEmpty\n\u001b[0;32m   2656\u001b[0m     )\n\u001b[0;32m   2657\u001b[0m loop\u001b[38;5;241m.\u001b[39mafter_tick()\n",
      "File \u001b[1;32md:\\python_exercises\\env\\lib\\site-packages\\langgraph\\pregel\\_runner.py:162\u001b[0m, in \u001b[0;36mPregelRunner.tick\u001b[1;34m(self, tasks, reraise, timeout, retry_policy, get_waiter, schedule_task)\u001b[0m\n\u001b[0;32m    160\u001b[0m t \u001b[38;5;241m=\u001b[39m tasks[\u001b[38;5;241m0\u001b[39m]\n\u001b[0;32m    161\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 162\u001b[0m     \u001b[43mrun_with_retry\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    163\u001b[0m \u001b[43m        \u001b[49m\u001b[43mt\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    164\u001b[0m \u001b[43m        \u001b[49m\u001b[43mretry_policy\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    165\u001b[0m \u001b[43m        \u001b[49m\u001b[43mconfigurable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m{\u001b[49m\n\u001b[0;32m    166\u001b[0m \u001b[43m            \u001b[49m\u001b[43mCONFIG_KEY_CALL\u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mpartial\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    167\u001b[0m \u001b[43m                \u001b[49m\u001b[43m_call\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    168\u001b[0m \u001b[43m                \u001b[49m\u001b[43mweakref\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mref\u001b[49m\u001b[43m(\u001b[49m\u001b[43mt\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    169\u001b[0m \u001b[43m                \u001b[49m\u001b[43mretry_policy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mretry_policy\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    170\u001b[0m \u001b[43m                \u001b[49m\u001b[43mfutures\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mweakref\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mref\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfutures\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    171\u001b[0m \u001b[43m                \u001b[49m\u001b[43mschedule_task\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mschedule_task\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    172\u001b[0m \u001b[43m                \u001b[49m\u001b[43msubmit\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msubmit\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    173\u001b[0m \u001b[43m            \u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    174\u001b[0m \u001b[43m        \u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    175\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    176\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcommit(t, \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[0;32m    177\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m exc:\n",
      "File \u001b[1;32md:\\python_exercises\\env\\lib\\site-packages\\langgraph\\pregel\\_retry.py:42\u001b[0m, in \u001b[0;36mrun_with_retry\u001b[1;34m(task, retry_policy, configurable)\u001b[0m\n\u001b[0;32m     40\u001b[0m     task\u001b[38;5;241m.\u001b[39mwrites\u001b[38;5;241m.\u001b[39mclear()\n\u001b[0;32m     41\u001b[0m     \u001b[38;5;66;03m# run the task\u001b[39;00m\n\u001b[1;32m---> 42\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtask\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mproc\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minvoke\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtask\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minput\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     43\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m ParentCommand \u001b[38;5;28;01mas\u001b[39;00m exc:\n\u001b[0;32m     44\u001b[0m     ns: \u001b[38;5;28mstr\u001b[39m \u001b[38;5;241m=\u001b[39m config[CONF][CONFIG_KEY_CHECKPOINT_NS]\n",
      "File \u001b[1;32md:\\python_exercises\\env\\lib\\site-packages\\langgraph\\_internal\\_runnable.py:657\u001b[0m, in \u001b[0;36mRunnableSeq.invoke\u001b[1;34m(self, input, config, **kwargs)\u001b[0m\n\u001b[0;32m    655\u001b[0m     \u001b[38;5;66;03m# run in context\u001b[39;00m\n\u001b[0;32m    656\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m set_config_context(config, run) \u001b[38;5;28;01mas\u001b[39;00m context:\n\u001b[1;32m--> 657\u001b[0m         \u001b[38;5;28minput\u001b[39m \u001b[38;5;241m=\u001b[39m context\u001b[38;5;241m.\u001b[39mrun(step\u001b[38;5;241m.\u001b[39minvoke, \u001b[38;5;28minput\u001b[39m, config, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    658\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    659\u001b[0m     \u001b[38;5;28minput\u001b[39m \u001b[38;5;241m=\u001b[39m step\u001b[38;5;241m.\u001b[39minvoke(\u001b[38;5;28minput\u001b[39m, config)\n",
      "File \u001b[1;32md:\\python_exercises\\env\\lib\\site-packages\\langgraph\\_internal\\_runnable.py:401\u001b[0m, in \u001b[0;36mRunnableCallable.invoke\u001b[1;34m(self, input, config, **kwargs)\u001b[0m\n\u001b[0;32m    399\u001b[0m         run_manager\u001b[38;5;241m.\u001b[39mon_chain_end(ret)\n\u001b[0;32m    400\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 401\u001b[0m     ret \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfunc(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    402\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrecurse \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(ret, Runnable):\n\u001b[0;32m    403\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m ret\u001b[38;5;241m.\u001b[39minvoke(\u001b[38;5;28minput\u001b[39m, config)\n",
      "Cell \u001b[1;32mIn[8], line 15\u001b[0m, in \u001b[0;36mSummariseWithLLM\u001b[1;34m(state)\u001b[0m\n\u001b[0;32m     12\u001b[0m chain \u001b[38;5;241m=\u001b[39m LLMChain(prompt\u001b[38;5;241m=\u001b[39mprompt, llm\u001b[38;5;241m=\u001b[39mllm_model)\n\u001b[0;32m     14\u001b[0m result \u001b[38;5;241m=\u001b[39m chain\u001b[38;5;241m.\u001b[39minvoke({\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124messay\u001b[39m\u001b[38;5;124m\"\u001b[39m: state[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124messay\u001b[39m\u001b[38;5;124m\"\u001b[39m]})\n\u001b[1;32m---> 15\u001b[0m parsed \u001b[38;5;241m=\u001b[39m \u001b[43mjson\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mloads\u001b[49m\u001b[43m(\u001b[49m\u001b[43mresult\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtext\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     17\u001b[0m state[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfeedback\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m parsed[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfeedback\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[0;32m     18\u001b[0m state[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mscore\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m parsed[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mscore\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\json\\__init__.py:346\u001b[0m, in \u001b[0;36mloads\u001b[1;34m(s, cls, object_hook, parse_float, parse_int, parse_constant, object_pairs_hook, **kw)\u001b[0m\n\u001b[0;32m    341\u001b[0m     s \u001b[38;5;241m=\u001b[39m s\u001b[38;5;241m.\u001b[39mdecode(detect_encoding(s), \u001b[38;5;124m'\u001b[39m\u001b[38;5;124msurrogatepass\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m    343\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\u001b[38;5;28mcls\u001b[39m \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m object_hook \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m\n\u001b[0;32m    344\u001b[0m         parse_int \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m parse_float \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m\n\u001b[0;32m    345\u001b[0m         parse_constant \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m object_pairs_hook \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m kw):\n\u001b[1;32m--> 346\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_default_decoder\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdecode\u001b[49m\u001b[43m(\u001b[49m\u001b[43ms\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    347\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mcls\u001b[39m \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    348\u001b[0m     \u001b[38;5;28mcls\u001b[39m \u001b[38;5;241m=\u001b[39m JSONDecoder\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\json\\decoder.py:337\u001b[0m, in \u001b[0;36mJSONDecoder.decode\u001b[1;34m(self, s, _w)\u001b[0m\n\u001b[0;32m    332\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mdecode\u001b[39m(\u001b[38;5;28mself\u001b[39m, s, _w\u001b[38;5;241m=\u001b[39mWHITESPACE\u001b[38;5;241m.\u001b[39mmatch):\n\u001b[0;32m    333\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Return the Python representation of ``s`` (a ``str`` instance\u001b[39;00m\n\u001b[0;32m    334\u001b[0m \u001b[38;5;124;03m    containing a JSON document).\u001b[39;00m\n\u001b[0;32m    335\u001b[0m \n\u001b[0;32m    336\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 337\u001b[0m     obj, end \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mraw_decode\u001b[49m\u001b[43m(\u001b[49m\u001b[43ms\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43midx\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m_w\u001b[49m\u001b[43m(\u001b[49m\u001b[43ms\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mend\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    338\u001b[0m     end \u001b[38;5;241m=\u001b[39m _w(s, end)\u001b[38;5;241m.\u001b[39mend()\n\u001b[0;32m    339\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m end \u001b[38;5;241m!=\u001b[39m \u001b[38;5;28mlen\u001b[39m(s):\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\json\\decoder.py:355\u001b[0m, in \u001b[0;36mJSONDecoder.raw_decode\u001b[1;34m(self, s, idx)\u001b[0m\n\u001b[0;32m    353\u001b[0m     obj, end \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mscan_once(s, idx)\n\u001b[0;32m    354\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mStopIteration\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n\u001b[1;32m--> 355\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m JSONDecodeError(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mExpecting value\u001b[39m\u001b[38;5;124m\"\u001b[39m, s, err\u001b[38;5;241m.\u001b[39mvalue) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    356\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m obj, end\n",
      "\u001b[1;31mJSONDecodeError\u001b[0m: Expecting value: line 1 column 1 (char 0)"
     ]
    }
   ],
   "source": [
    "result = Workflow.invoke({\n",
    "    \"essay\": essay,\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4907a662",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a158916",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
